{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DESENVOLVENDO SCRIPT PARA LER A IMAGEM E EXTRAIR INFORMACOES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_beija_flor = r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte1-Filtros\\images\\beija-flor.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte1-Filtros\\images\\estrada.jpg')\n",
    "print(f'ESTA IMAGEM É UM OBJETO {type(img)}, com a seguinte dimensoes: {img.shape}')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsize, ysize = img.shape[0], img.shape[1]\n",
    "print(f'LINHAS:{xsize} COLUNAS:{ysize}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_select = np.copy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterio de selecao de cores\n",
    "fix = 200\n",
    "red_threshold = fix\n",
    "green_threshold = fix\n",
    "blue_threshold = fix \n",
    "rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "print(rgb_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = (img[:,:,0] < rgb_threshold[0]) \\\n",
    "            | (img[:,:,1] < rgb_threshold[1]) \\\n",
    "            | (img[:,:,2] < rgb_threshold[2])\n",
    "color_select[thresholds] = [0, 0, 0]\n",
    "plt.imshow(color_select)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# APLICANDOO  FILTRO NA IMAGEM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## UTILIZANDO O PIL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_beija_flor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.filter(ImageFilter.MedianFilter(11))\n",
    "img.show()"
   ]
  },
  {
   "source": [
    "## UTILIZANDO O OPENCV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('IMG ORIGINAL', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = np.hstack([cv2.medianBlur(img, 3), cv2.medianBlur(img, 5), cv2.medianBlur(img, 7)])\n",
    "cv2.imshow('IMG BLUR', blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# MEDIA MODERADA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## APLICANDO NO PIL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_beija_flor)\n",
    "img = img.filter(ImageFilter.GaussianBlur(3))\n",
    "img.show()"
   ]
  },
  {
   "source": [
    "## APLICANDO NO CV2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "kernels = [(3, 3), (9, 9), (15, 15), (21, 21)]\n",
    "\n",
    "for (kX, kY) in kernels:\n",
    "    blurred = cv2.blur(img, (kX, kY))\n",
    "    cv2.imshow(f'IMG BLUR({kX}{kY})', blurred)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# OPERACAOES MORFOLOGICAS (EROSAO E DILATACAO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## EROSAO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('IMG ORIGINAL CINZA', gray)\n",
    "cv2.waitKey(0)\n",
    "for i in range(0, 5):\n",
    "    erosao = cv2.erode(gray.copy() , None, iterations=i + 1) # parametros: uma copia da img, kernel, interacao\n",
    "    cv2.imshow(f'EROSAO {i} IMG', erosao)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "## DILATACAO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    dilatacao = cv2.dilate(gray.copy(), None, iterations=i+1)# parametros: uma copia da img, kernel, interacao\n",
    "    cv2.imshow(f'DILATACAO {i} IMG', dilatacao)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# FILTRO PERSONALIZADOS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_beija_flor)\n",
    "kernal = ImageFilter.Kernel((3, 3), [1, 0, -1, 5, 0, -5, 1, 0, 1])\n",
    "print(kernal)\n",
    "img = img.filter(kernal)\n",
    "img.show()"
   ]
  },
  {
   "source": [
    "# THRESHOLD\n",
    "### O CONCEITO DE THRESHOLD É SEPARAR A IMAGEM DE FUNDO COM A IMAGEM DE INTERESSE. PARA ISSO PODE SE BINARIZAR A IMAGEM E ATRIBUIR DUAS CORES PARA DESTACAR O QUE NÃO É RELEVANTE DO QUE É. NORMALMENTE ATRAVÉS DE UMA OPERAÇÃO DE HISTOGRAMA O ALGORITIMO PEGA O VALOR MEDIO DO GRAFICO PARA CRIAR O THESHOLD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#ATRAVES DO FILTRO GAUSIANO, PODEMOS TER UMA PREPARACAO PARA EXTRAIR O QUE DESEJAMOS. TAMBÉM É UTIL PARA SUAVISAR OS EXCESSO DE PIXELIS NA IMAGEM. SEM ISSO A IMAGEM CORRE O RISCO DE FICAR MUITO CLARA.\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "cv2.imshow('IMG COM FILTRO GAUSSIANO', blurred)\n",
    "\n",
    "(T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)# PARAMETROS: imagem, limite (limiar), se o valor do pixel for maior que o limiar convertemos para BRANCO, caso contrario para preto. O proximo parametro e o valor que vai ser usado para valores acima do campo anterior. O ultimo campo vai ser o algoritimo que vai ser usado. Veja que abaixo ele vai fazer o mesmo só que invertendo o resultado.\n",
    "cv2.imshow('IMAGEM BINARIZADA COM THRESHOLD', thresh)\n",
    "\n",
    "(T, threshoInv) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('IMAGEM BINARIZADA COM THRESHOLD INVERTIDA', threshoInv)\n",
    "\n",
    "cv2.imshow('CASAS DECIMAIS', cv2.bitwise_and(img, img, mask=threshoInv))\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### NA IMAGEM DA CELULA ACIMA VIMOS UM DEFEITO MUITO SERIO NA QUESTÃO DA PERCA DOS DETALHES, ISSO ACONTECE POR CONTA DO VALOR DE THRESHOLD(155) QUE NAO FOI O MELHOR VALOR, ISSO OCASIONA DE FICAR TENTANDO ENCONTRAR UM VALOR QUE SEJA MAIS ADEQUADO. PARA RESOLVER ISSO O CV2 TEM UMA FORMA DE ENCONTRAR DE FORMA INTELIGENTE."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "cv2.imshow('IMAGEM ORIGINAL', blurred)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)\n",
    "\n",
    "cv2.imshow('IMAGEM THRESHOLD', thresh)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\n",
    "\n",
    "cv2.imshow('GAUSSIANA THRESHOLD', thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# DETECCAO DE BORDAS(SOBEL)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\mini projeto\\imagens_teste\\imagem2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow('IMAGEM ORIGINAL', gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "#COMPUTA OS GRADIENTES\n",
    "gX = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=1, dy=0)\n",
    "gY = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=0, dy=1)\n",
    "print(gX, gY, type(gX), type(gY))\n",
    "# AS IMAGENS gX e gY  SAO NUMEROS FLUTUANTES, PRECISAMOS CONVERTER NOVAMENTE\n",
    "\n",
    "gX = cv2.convertScaleAbs(gX)\n",
    "gY = cv2.convertScaleAbs(gY)\n",
    "\n",
    "#COBINA AS REPRETACOES Sobel x e y em uma unica imagems\n",
    "sobelCombinado = cv2.addWeighted(gX, 0.5, gY, 0.5, 0)\n",
    "\n",
    "cv2.imshow('SOBEL X', gX)\n",
    "cv2.imshow('SOBEL Y', gY)\n",
    "cv2.imshow('SOBEL COMBINADO', sobelCombinado)\n",
    "cv2.waitKey(0)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# CALCULAR O GRADIENTE DE X E Y PARA DETECTAR DENTRO DA BORDA(MAGNITUDE E ORIENTACAO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_beija_flor)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('ORIGINAL', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#COMPUTADONDO O GRADIENTE DE X E Y\n",
    "gX = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "gY = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "\n",
    "mag = np.sqrt((gX ** 2) + (gY ** 2))\n",
    "orientacao = np.arctan2(gY, gX) * (180 / np.pi) % 180\n",
    "print(f'mag: {mag} orientacao: {orientacao}')\n",
    "\n",
    "#ENCONTRAR TODOS OS PIXELS QUE ESTAO DENTRO DOS LMITES DOS ANGULOS\n",
    "idx = np.where(orientacao >= 175.0, orientacao, -1)\n",
    "idx = np.where(orientacao <= 180.0, idx, -1)\n",
    "\n",
    "mascara = np.zeros(gray.shape, dtype='uint8')\n",
    "mascara[idx > -1] = 255\n",
    "\n",
    "cv2.imshow('BORDAS DA IMAGEM', mascara)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "source": [
    "# CANNY ADGE DECTETOR (DETECTOR DE BORDAS)\n",
    "### ACRESCENTA ALGUMAS ETAPAS PARA ENCONTRAR AS BORDAS:\n",
    "### 1 SUAVIZACAO DAS BORDAS\n",
    "### 2 ENCONTRAMOS O GRADIENTES\n",
    "### 3 VERIFICAR SE O GRADIENTE CALCULADO TEM PONTOS VISINHOS \n",
    "### 4 THRESHOLD (LIMITE LIMIAR)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte1-Filtros\\images\\estrada.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# REALIZA A DESFOCAGEM OU SUAVIZACAO DAS BORDAS\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "cv2.imshow('ORIGINAL', blurred)\n",
    "\n",
    "# CALCULA UM LIMITE 'WIDE', 'MID-RANGE' E 'TIGHT' PARA AS BORDAS\n",
    "wide = cv2.Canny(blurred, 10, 200)\n",
    "mid = cv2.Canny(blurred, 30, 150)\n",
    "tight = cv2.Canny(blurred, 240, 250)\n",
    "\n",
    "cv2.imshow('IMAGEM WIDE', wide)\n",
    "cv2.imshow('IMAGEM MID', mid)\n",
    "cv2.imshow('IMAGEM TIGHT', tight)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFININDO O VALOR AUTOMATICO PARA ELE ENCONTRAR AS BORDAS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "def autoCanny(img, sigma=.33):\n",
    "    'APLICA A MEDIANA ATRAVES DA INTENSIDADES DE PIXEL DE UM UNICO CANAL'\n",
    "    v = np.median(img)\n",
    "    'APLICANDO A DETECCAO AUTOMATICA DE BORDAS CANNY USANDO A MEDIANA'\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(img, lower, upper)\n",
    "    return edged\n",
    "\n",
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte1-Filtros\\images\\casa.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "#APLICANDO OS CANNY ANTERIORES E O AUTOCANNY PARA PERCEBER A DIFERENCA\n",
    "wide = cv2.Canny(blurred, 10, 200)\n",
    "tight = cv2.Canny(blurred, 255, 250)\n",
    "auto = autoCanny(blurred)\n",
    "\n",
    "cv2.imshow('IMG ORIGINAL', blurred)\n",
    "cv2.imshow('IMG WIDE', wide)\n",
    "cv2.imshow('IMG TIGHT', tight)\n",
    "cv2.imshow('IMG AUTO', auto)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# DESENHAR SOBRE A BORDAS ENCONTRADAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ENCONTRADO 327 CONTORNOS\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "def autoCanny(img, sigma=.33):\n",
    "    'APLICA A MEDIANA ATRAVES DA INTENSIDADES DE PIXEL DE UM UNICO CANAL'\n",
    "    v = np.median(img)\n",
    "    'APLICANDO A DETECCAO AUTOMATICA DE BORDAS CANNY USANDO A MEDIANA'\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(img, lower, upper)\n",
    "    return edged\n",
    "\n",
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\mini projeto\\imagens_teste\\imagem2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "'DESFOCAGEM'\n",
    "blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "\n",
    "'CANNY'\n",
    "edged = autoCanny(blurred)\n",
    "\n",
    "cv2.imshow('IMG ORIGINAL', img)\n",
    "cv2.waitKey(0)\n",
    "#ENCONTRA TODOS OS CONTORNOS NA IMAGEM E DESENHA TODOS OS CONTORNOS NA IMAGEM\n",
    "(_, cnts) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # PARAMETROS: UMA COPIA DA IMAGEM, FLAG QUE GARANTE TODOS OS CONTORNOS, RETORNA OS DETALHES MAIS SIMPLES DOS PIXELS.\n",
    "\n",
    "#FUNCAO findCountrs É DESTRUTIVA, OU SEJA, ELA ALTERA A IMAGEM. POR ISSO FAZEMOS UMA COPIA DA IMAGEM\n",
    "\n",
    "clone = img.copy()\n",
    "\n",
    "#DESENHAR OS CONTORNOS\n",
    "cv2.drawContours(clone, _, -1, (0, 255, 0), 2) # PARAMETROS: 1- IMAGEM, 2 - LISTA DE CONTORNOS, 4 - COR DESEJADA\n",
    "print(f'ENCONTRADO {len(_)} CONTORNOS')\n",
    "\n",
    "cv2.imshow('IMAGEM COM CONTORNOS', clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "source": [
    "# CONTAGEM DE OBJETOS NA IMAGEM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CONTORNO 1 AREA 200646.0 PERIMETRO 1906.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte2-EdgeDetection\\images\\shapes.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#DESSA VEZ ESTOU PEGANDO A BORDA EXTERNA\n",
    "qtde, _ = cv2.findContours(gray.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "clone = img.copy()\n",
    "\n",
    "for (i, c) in enumerate(qtde):\n",
    "    # CALCULA AREA E PERIMETRO DO CONTORNO\n",
    "    area = cv2.contourArea(c)\n",
    "    perimetro = cv2.arcLength(c, True)\n",
    "    print(f'CONTORNO {i+1} AREA {area} PERIMETRO {perimetro}')\n",
    "\n",
    "    #DESENHANDO O CONTORNO NA IMAGEM\n",
    "    cv2.drawContours(clone, [c], -1, (0, 255, 0), 2)\n",
    "\n",
    "    #CALCULANDO O CENTRO DO CONTORNO E DESENHA O NUMERO DO CONTORNO\n",
    "    m = cv2.moments(c)\n",
    "    cX = int(m['m10'] / m['m00'])\n",
    "    cY = int(m['m01'] / m['m00'])\n",
    "    cv2.putText(clone, f'{i+1}', (cX - 20, cY), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (255, 255, 255), 4)\n",
    "\n",
    "cv2.imshow('IMAGEM CONTADA', clone)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "# VERIFICANDO SE O OBJETO É RETANGULO OU \n",
    "img = cv2.imread(r'C:\\Users\\Plus-TI\\Documents\\APRENDIZAGEM\\OPENCV\\Parte2-EdgeDetection\\images\\shapes.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "(qtde, _) = cv2.findContours(gray.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# SEGUIR COM A CONTAGEM E DESENHAR O CONTORNO\n",
    "for cc, c in enumerate(qtde):\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "\n",
    "    #SE O CONTORNO TIVER 4 VERTICES ENTÃO ESTAMOS EXAMINANDO UM RETANGULO\n",
    "    if(len(approx) == 4):\n",
    "        cv2.drawContours(img, [c], -1, (0, 255, 0), 2)\n",
    "        (x, y, w, h) = cv2.boundingRect(approx)\n",
    "        cv2.putText(img, f'RETANGULO({cc})', (x, y - 10),       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.drawContours(img, [c], -1, (255, 0, 0), 2)\n",
    "        (x, y, w, h) = cv2.boundingRect(approx)\n",
    "        cv2.putText(img, f'PROVAVEL CIRCULO:({cc})', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "cv2.imshow('IMAGEM COM A CONTAGEM E VERICACAO', img)\n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "source": [
    "### CAPTURANDO COM WEBCAM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    rect, frame = captura.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    wide = cv2.Canny(blurred, 10, 200)\n",
    "\n",
    "    cv2.imshow('IMAGEM', wide)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if(k == 27): break\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}